{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcZ4fuzPlX0V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTd10fh6lfdy"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2U7igsFqlfiP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5VqwidGlfgr"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/My Drive/Datasets/MyDatasets/PlantVillage\"\n",
        "\n",
        "classes = [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name))]\n",
        "\n",
        "class_name = random.choice(classes)\n",
        "class_path = os.path.join(path, class_name)\n",
        "img_name = random.choice(os.listdir(class_path))\n",
        "img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "img = Image.open(img_path)\n",
        "\n",
        "print(f\"Number of total classes: {len(classes)}\")\n",
        "print(class_name)\n",
        "print(img.height)\n",
        "print(img.width)\n",
        "\n",
        "img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrKcSzi5mpwX"
      },
      "outputs": [],
      "source": [
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=1.0),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uz3HaM84mpzi"
      },
      "outputs": [],
      "source": [
        "def visualize_transform(img_path, transform):\n",
        "    img = Image.open(img_path)\n",
        "    print(img)\n",
        "    transformed_img = transform(img)\n",
        "    print(transformed_img)\n",
        "\n",
        "    if isinstance(transformed_img, torch.Tensor):\n",
        "        transformed_img = transforms.ToPILImage()(transformed_img)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title(\"Original\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    axes[1].imshow(transformed_img)\n",
        "    axes[1].set_title(\"Transformed\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiKG5uFbmp2J"
      },
      "outputs": [],
      "source": [
        "class_name = random.choice(classes)\n",
        "class_path = os.path.join(path, class_name)\n",
        "img_name = random.choice(os.listdir(class_path))\n",
        "img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "visualize_transform(img_path, data_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPrIT6pOlfrj"
      },
      "outputs": [],
      "source": [
        "full_dataset = datasets.ImageFolder(root=path, transform=None)\n",
        "full_dataset\n",
        "\n",
        "class_to_idx = full_dataset.class_to_idx\n",
        "idx_to_class = {value: key for key, value in class_to_idx.items()}\n",
        "classes = list(class_to_idx.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3Nv6EjzlfvR"
      },
      "outputs": [],
      "source": [
        "targets = [sample[1] for sample in full_dataset.samples]\n",
        "\n",
        "train_idx, test_idx = train_test_split(\n",
        "    np.arange(len(targets)),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=targets\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCPgxY3glfzf"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of Train images: {len(train_idx)} | Number of Test images: {len(test_idx)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQG09sEalf4J"
      },
      "outputs": [],
      "source": [
        "temp_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "temp_full = datasets.ImageFolder(root=path, transform=temp_transform)\n",
        "temp_train = Subset(temp_full, train_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doIdGIOllf6-"
      },
      "outputs": [],
      "source": [
        "def get_mean_std(dataset, batch_size=16, num_workers=2):\n",
        "  loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
        "  rgb_sum = torch.zeros(3)\n",
        "  rgb_sumsq = torch.zeros(3)\n",
        "  count_pixels = 0\n",
        "\n",
        "  for x, _ in loader:\n",
        "    b, c, h, w = x.shape\n",
        "    count_pixels += b * h * w\n",
        "    rgb_sum += x.sum(dim=[0, 2, 3])\n",
        "    rgb_sumsq += (x**2).sum(dim=[0, 2, 3])\n",
        "\n",
        "  mean = rgb_sum / count_pixels\n",
        "  std = torch.sqrt(rgb_sumsq / count_pixels - mean **2)\n",
        "  return mean, std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loE2rVyBlf-q"
      },
      "outputs": [],
      "source": [
        "# mean_tensor, std_tensor = get_mean_std(temp_train)\n",
        "# mean = mean_tensor.list()\n",
        "# std = std_tensor.list()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0.4592542350292206, 0.4754604697227478, 0.4115070700645447]\n",
        "std = [0.1860169768333435, 0.16259966790676117, 0.20085515081882477]"
      ],
      "metadata": {
        "id": "argxjZ7KVojy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJcaSY4MlgCA"
      },
      "outputs": [],
      "source": [
        "# mean = [0.5, 0.5, 0.5]\n",
        "# std = [0.5, 0.5, 0.5]\n",
        "# mean,std= get_mean_std(temp_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzcXmoknqg9F"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbza5JkrqhAo"
      },
      "outputs": [],
      "source": [
        "train_data_all = datasets.ImageFolder(root=path, transform=train_transform)\n",
        "test_data_all = datasets.ImageFolder(root=path, transform=test_transform)\n",
        "\n",
        "train_set = Subset(train_data_all,train_idx)\n",
        "test_set = Subset(test_data_all,test_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpdO5UkHqhD0"
      },
      "outputs": [],
      "source": [
        "len(train_set), len( test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXDBLvixqhGY"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMuTzoKhqhJQ"
      },
      "outputs": [],
      "source": [
        "len(train_loader), len(test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmO8mX8oqhL4"
      },
      "outputs": [],
      "source": [
        "class SampleCNN(nn.Module):\n",
        "  def __init__(self, input_shape, output_shape, hidden_units):\n",
        "    super().__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCGgaByWqhT7"
      },
      "outputs": [],
      "source": [
        "input_shape = 3*224*224\n",
        "output_shape = 15\n",
        "hidden_units = 256\n",
        "\n",
        "sampleCnn = SampleCNN(input_shape, output_shape, hidden_units)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampleCnn"
      ],
      "metadata": {
        "id": "cVRkG7ufO10g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class newCNN(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super.__init__()\n",
        "\n",
        "    self.block1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2)\n",
        "    )\n",
        "\n",
        "    self.block2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2)\n",
        "    )\n",
        "\n",
        "    self.block3 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=128*28*28, out_features=512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(in_features=512, out_features=num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "    # return self.classifier(self.block3(self.block2(self.block1(x))))"
      ],
      "metadata": {
        "id": "gbWgZytlO1-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model= sampleCnn"
      ],
      "metadata": {
        "id": "YbWxp8ssNIp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=0.001)\n",
        "\n",
        "#Move model to GPU if available\n",
        "mlp_model = mlp_model.to(device)\n",
        "\n",
        "# Training and Evaluation Loop\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  # Training Phase\n",
        "  mlp_model.train()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  # tqdm progress bar\n",
        "  for batch_idx, (X_batch, y_batch) in enumerate (tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=True)):\n",
        "    X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "    #forward pass\n",
        "    y_pred = mlp_model(X_batch)\n",
        "    loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "    #backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #running metrics\n",
        "    running_loss += loss.item()\n",
        "    _, predicted = torch.max(y_pred, 1)\n",
        "    total += y_batch.size(0)\n",
        "    correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "    #batch-wise loss print every 50 batches\n",
        "    if batch_idx % 50 == 0:\n",
        "        tqdm.write(f\"Batch {batch_idx}: Loss={loss.item():.4f}\")\n",
        "\n",
        "  #Epoch-wise metrics\n",
        "  train_acc = 100 * correct / total\n",
        "  avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "  # Evaluation Phase\n",
        "  mlp_model.eval()\n",
        "  test_correct = 0\n",
        "  test_total = 0\n",
        "  test_loss_total = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            test_pred = mlp_model(X_batch)\n",
        "            test_loss = loss_fn(test_pred, y_batch)\n",
        "\n",
        "            test_loss_total += test_loss.item()\n",
        "            _, predicted = torch.max(test_pred, 1)\n",
        "            test_total += y_batch.size(0)\n",
        "            test_correct += (predicted == y_batch).sum().item()\n",
        "\n",
        "  test_acc = 100 * test_correct / test_total\n",
        "  avg_test_loss = test_loss_total / len(test_loader)\n",
        "\n",
        "  #print epoch summary\n",
        "  print(f\"Epoch [{epoch+1}/{EPOCHS}] | Loss: {avg_loss:.4f} | Train Acc: {train_acc:.2f}% | Test Acc: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "BTNUPc7YMfC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save model weights\n",
        "torch.save(mlp_model.state_dict(), \"/content/drive/MyDrive/mlp_model.pth\")\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "id": "QOG1dhUgMfK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = SampleCNN(input_shape = 3*224*224, output_shape = 15, hidden_units = 256)\n",
        "mlp_model.load_state_dict(torch.load(\"/content/drive/MyDrive/mlp_model.pth\"))\n",
        "mlp_model.to(device)\n",
        "mlp_model.eval()\n",
        "\n",
        "print(\"Trained model loaded successfully!\")"
      ],
      "metadata": {
        "id": "_98naaO6MfOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"ButterChicken98/plantvillage-image-text-pairs\")"
      ],
      "metadata": {
        "id": "ARt_dm2DMfRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.save_to_disk(\"/content/sample_data/text\")"
      ],
      "metadata": {
        "id": "oV2GyDttMfVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 1. Training loop function\n",
        "def train_model(model, dataloader, criterion, optimizer, device, num_epochs=5):\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track loss and accuracy\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "    print(\"Training finished \")\n",
        "    return model"
      ],
      "metadata": {
        "id": "3q62IkJ3abt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SampleNN(nn.Module):\n",
        "    def __init__(self, input_size=3*64*64, num_classes=10):\n",
        "        super(SampleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)   # flatten\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cmvZ3NiZabxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 16 * 16, 128)  # assumes input 3x64x64\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "QlllZkWuab0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "#Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Dataset & DataLoader\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # normalize images\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "#Define models\n",
        "class SampleNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SampleNN, self).__init__()\n",
        "        self.fc = nn.Linear(28*28, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # flatten\n",
        "        return self.fc(x)\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(32*14*14, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc1(x)\n",
        "\n",
        "#Training function\n",
        "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=5):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "#Train Sample NN\n",
        "sample_model = SampleNN(num_classes=10)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(sample_model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"\\n🔹 Training Sample Neural Network...\")\n",
        "train_model(sample_model, train_loader, criterion, optimizer, device, num_epochs=5)\n",
        "\n",
        "#Train CNN\n",
        "cnn_model = SimpleCNN(num_classes=10)\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"\\n🔹 Training CNN...\")\n",
        "train_model(cnn_model, train_loader, criterion, optimizer, device, num_epochs=5)"
      ],
      "metadata": {
        "id": "pgQ6JO8Sab4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=5):\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "id": "2R7GmMqVab69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "small_dataset = Subset(train_dataset, range(2000))  # only 2k images\n",
        "train_loader = DataLoader(small_dataset, batch_size=32, shuffle=True)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((16, 16)),  # even smaller\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "SX3tcBxtab9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "#Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Path to dataset and model file\n",
        "data_path = \"/content/drive/My Drive/Datasets/MyDatasets/PlantVillage\"\n",
        "model_path = \"/content/drive/MyDrive/plant_cnn_128.pth\"\n",
        "\n",
        "#Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # for RGB\n",
        "])\n",
        "\n",
        "#Dataset + split\n",
        "dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"Found {len(dataset)} images across {len(dataset.classes)} classes.\")\n",
        "\n",
        "#Model\n",
        "class BetterCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(BetterCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 32 * 32, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))   # 128 -> 64\n",
        "        x = self.pool(self.relu(self.conv2(x)))   # 64 -> 32\n",
        "        x = self.relu(self.conv3(x))              # keep 32\n",
        "        x = self.relu(self.conv4(x))              # keep 32\n",
        "        x = x.view(x.size(0), -1)                 # flatten\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "#Training loop\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=5):\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        correct, total = 0, 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct, val_total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "                outputs = model(images)\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += predicted.eq(labels).sum().item()\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "#Train once or load directly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = len(dataset.classes)\n",
        "model = BetterCNN(num_classes=num_classes)\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    #Load saved model instead of retraining\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"Model loaded from Drive (no retraining).\")\n",
        "else:\n",
        "    # Train and save (only the first time)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    print(\"Training model (this will take time once)...\")\n",
        "    train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=5)\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(\" Model saved to Drive.\")"
      ],
      "metadata": {
        "id": "jzdhf_z0acAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from google.colab import drive\n",
        "\n",
        "#Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Path to dataset\n",
        "data_path = \"/content/drive/My Drive/Datasets/MyDatasets/PlantVillage\"\n",
        "\n",
        "# Transform → resize to 128x128\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # for RGB\n",
        "])\n",
        "\n",
        "#Dataset + split into train/val\n",
        "dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"Found {len(dataset)} images across {len(dataset.classes)} classes.\")\n",
        "\n",
        "#Better CNN for 128x128\n",
        "class BetterCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(BetterCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)   # 128 -> 128\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)  # 128 -> 128\n",
        "        self.pool = nn.MaxPool2d(2, 2)                # halves size\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)  # 64 -> 64\n",
        "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1) # 64 -> 64\n",
        "\n",
        "        # after 2 poolings: 128 -> 32\n",
        "        self.fc1 = nn.Linear(128 * 32 * 32, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))   # 128 -> 64\n",
        "        x = self.pool(self.relu(self.conv2(x)))   # 64 -> 32\n",
        "        x = self.relu(self.conv3(x))              # keep 32\n",
        "        x = self.relu(self.conv4(x))              # keep 32\n",
        "        x = x.view(x.size(0), -1)                 # flatten\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "#Training loop with accuracy\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=5):\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        correct, total, running_loss = 0, 0, 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_correct, val_total, val_loss = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += predicted.eq(labels).sum().item()\n",
        "        val_acc = 100 * val_correct / val_total\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "              f\"Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "#Train\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = len(dataset.classes)\n",
        "model = BetterCNN(num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=5)\n",
        "\n",
        "#Save model\n",
        "torch.save(model.state_dict(), \"plant_cnn_128.pth\")\n",
        "print(\"Model saved as plant_cnn_128.pth\")"
      ],
      "metadata": {
        "id": "iwpaUlkpa8we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from google.colab import drive\n",
        "\n",
        "#Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Path to dataset\n",
        "data_path = \"/content/drive/My Drive/Datasets/MyDatasets/PlantVillage\"\n",
        "\n",
        "#Simple transform (smaller image size = faster training)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # 🔹 smaller size for speed\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "#Load dataset\n",
        "train_dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "print(f\"Found {len(train_dataset)} images in {len(train_dataset.classes)} classes.\")\n",
        "\n",
        "#Tiny models\n",
        "class SampleNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SampleNN, self).__init__()\n",
        "        self.fc = nn.Linear(32*32*3, num_classes)  # 🔹 just one layer (fast!)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv = nn.Conv2d(3, 8, 3, padding=1)   # 🔹 fewer filters\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc = nn.Linear(8 * 16 * 16, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "#Training loop (only 2 epochs for speed)\n",
        "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=2):\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "#Train both models quickly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"\\n🔹 Training Sample Neural Network...\")\n",
        "sample_model = SampleNN(num_classes=len(train_dataset.classes))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(sample_model.parameters(), lr=0.001)\n",
        "train_model(sample_model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "print(\"\\n🔹 Training Simple CNN...\")\n",
        "cnn_model = SimpleCNN(num_classes=len(train_dataset.classes))\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=0.001)\n",
        "train_model(cnn_model, train_loader, criterion, optimizer, device)"
      ],
      "metadata": {
        "id": "62dl3Sdpa8zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to dataset\n",
        "data_path = \"/content/drive/My Drive/Datasets/MyDatasets/PlantVillage\"\n",
        "\n",
        "# Simple transform (smaller image size = faster training)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # 🔹 smaller size for speed\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "train_dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Splitting the dataset into train and test sets\n",
        "# This assumes that you want to use a portion of the loaded data for testing as well.\n",
        "# If you have a separate test set folder, you would load it similarly.\n",
        "# For demonstration, I'll split the loaded dataset.\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "test_size = len(train_dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(train_dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the model (copied from cell 62dl3Sdpa8zF)\n",
        "class SampleNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SampleNN, self).__init__()\n",
        "        self.fc = nn.Linear(32*32*3, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)\n",
        "\n",
        "# Define the loss function and optimizer (copied from cell 62dl3Sdpa8zF)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "sample_model = SampleNN(num_classes=len(train_dataset.dataset.classes)) # Use train_dataset.dataset.classes to get the classes from the original dataset\n",
        "optimizer = optim.Adam(sample_model.parameters(), lr=0.001)\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = [] # Add a list to store test losses\n",
        "EPOCHS = 10 # Reduced epochs for demonstration\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    train_loss = 0\n",
        "\n",
        "    sample_model.train() # Set the model to training mode\n",
        "\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        y_pred = sample_model(X)\n",
        "\n",
        "        loss = criterion(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "    train_loss_history.append(avg_train_loss)\n",
        "\n",
        "    # Evaluation\n",
        "    sample_model.eval() # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    with torch.inference_mode(): # Turn off gradients for evaluation\n",
        "        for X_test, y_test in test_loader:\n",
        "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "            test_pred = sample_model(X_test)\n",
        "            loss = criterion(test_pred, y_test)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "        avg_test_loss = test_loss / len(test_loader)\n",
        "        test_loss_history.append(avg_test_loss)\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}/{EPOCHS}, Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}\")"
      ],
      "metadata": {
        "id": "mnFhvEfEa82H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "spJF9MLza84-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/Datasets/MyDatasets/PlantVillage\""
      ],
      "metadata": {
        "id": "9nSMyo9ca877"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "import cv2\n",
        "import random\n",
        "import os\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.utils import img_to_array, array_to_img\n",
        "from keras.preprocessing.image import img_to_array, array_to_img\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation,Flatten,Dropout,Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import model_from_json\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "uVSj737za8-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf. __version__)"
      ],
      "metadata": {
        "id": "VdN85kh8bUj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "path = \"/content/drive/MyDrive/Datasets/MyDatasets/PlantVillage/Potato___Early_blight\"\n",
        "for i in range(1,17):\n",
        "  plt.subplot(4,4,i)\n",
        "  plt.tight_layout()\n",
        "  rand_img = imread(path +'/'+ random.choice(sorted(os.listdir(path))))\n",
        "  plt.imshow(rand_img)\n",
        "  plt.xlabel(rand_img.shape[1], fontsize = 10)\n",
        "  plt.ylabel(rand_img.shape[0], fontsize = 10)"
      ],
      "metadata": {
        "id": "jvYENBTUbUms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a532c694"
      },
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/drive/My Drive/Datasets/MyDatasets/PlantVillage\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Coverting Images to array\n",
        "def convert_image_to_array(image_dir):\n",
        "  try:\n",
        "    image = cv2.imread(image_dir)\n",
        "    if image is not None:\n",
        "      image = cv2.resize(image,(256,256))\n",
        "      return img_to_array(image)\n",
        "    else :\n",
        "      return np.array([])\n",
        "  except Exception as e:\n",
        "    print(f\"Error : {e}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "Iwaasm6zbUpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"/content/drive/My Drive/Datasets/MyDatasets/PlantVillage\"\n",
        "image_list, label_list = [], []\n",
        "all_labels = ['Tomato_Bacterial_spot', 'Potato___Early_blight', 'Tomato_healthy']\n",
        "binary_labels = [0,1,2]\n",
        "temp = -1\n",
        "#Reading and converty image to numpy array\n",
        "for directory in ['Tomato_Bacterial_spot', 'Potato___Early_blight', 'Tomato_healthy']:\n",
        "  plant_image_list = listdir(f\"{dir}/{directory}\")\n",
        "  temp += 1\n",
        "  for files  in plant_image_list:\n",
        "    image_path = f\"{dir}/{directory}/{files}\"\n",
        "    image_list.append(convert_image_to_array(image_path))\n",
        "    label_list.append(binary_labels[temp])"
      ],
      "metadata": {
        "id": "UMYo9QdibUsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize the number of classes count\n",
        "label_counts = pd.DataFrame(label_list).value_counts()\n",
        "label_counts.head()"
      ],
      "metadata": {
        "id": "e3SbMM8FbUug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_list[0].shape"
      ],
      "metadata": {
        "id": "2h3k8Dv7bUxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(image_list, label_list, test_size=0.2, random_state=10)\n"
      ],
      "metadata": {
        "id": "-wzBZwg1bUzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train, dtype=np.float16) / 255.0\n",
        "x_test = np.array(x_test, dtype=np.float16) / 225.0\n",
        "x_train = x_train.reshape(-1,256,256,3)\n",
        "x_test = x_test.reshape(-1,256,256,3)"
      ],
      "metadata": {
        "id": "e1dBYKyAacCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "VXwLGfvnacKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=(256,256,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Conv2D(16, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(8, activation=\"relu\"))\n",
        "model.add(Dense(3, activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "TDI_ugqpbtpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer= Adam(0.0001),metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "nNl6SUeZbtsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.2,random_state=10)\n"
      ],
      "metadata": {
        "id": "WKQFQgdgbtu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=(256,256,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Conv2D(16, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation=\"relu\"))  # increased neurons for better learning\n",
        "model.add(Dense(15, activation=\"softmax\"))  # 15 classes instead of 3\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(0.0001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "p_oPKFwBbtxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# create data generator with rescaling\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# training set\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    \"/content/drive/My Drive/Datasets/MyDatasets/PlantVillage\",\n",
        "    target_size=(256, 256),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# validation set\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    \"/content/drive/My Drive/Datasets/MyDatasets/PlantVillage\",\n",
        "    target_size=(256, 256),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# fit model using generator\n",
        "epochs = 50\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "c0wgSMXsbt0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "JAqdyzC0bt26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_gray = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),  # Convert RGB → Gray\n",
        "    transforms.Resize((64, 64)),                # Resize all images\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])   # Normalize (gray has 1 mean/std)\n",
        "])"
      ],
      "metadata": {
        "id": "Eh-78Ra6bt5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/MyDrive/Datasets/MyDatasets/PlantVillage\""
      ],
      "metadata": {
        "id": "OLpb1hAnbt72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(root=data_path, transform=transform_gray)\n",
        "\n",
        "# Split dataset (80% train, 20% val)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size   = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"Classes:\", dataset.classes)  # Check labels"
      ],
      "metadata": {
        "id": "gzBseUt9cGRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 16 * 16, 128)   # smaller now\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "K5FKj75ocGT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "small_train, _ = random_split(train_dataset, [2000, len(train_dataset)-2000])\n",
        "train_loader = DataLoader(small_train, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "ARmBvp4TcGWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Training on:\", device)"
      ],
      "metadata": {
        "id": "YUdCWKpJcGZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_gray = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "f11lCbptcGb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)   # 1 channel for gray\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 32 * 32, 128)       # depends on image size\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "BWsjlaGgcP6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UA8QiOI1cP9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Training on:\", device)"
      ],
      "metadata": {
        "id": "20xr_edccQAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Config: choose RGB or Gray\n",
        "use_gray = True   # set False if you want RGB\n",
        "\n",
        "if use_gray:\n",
        "    channels = 1\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((128, 128)),   # now 128×128\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    ])\n",
        "else:\n",
        "    channels = 3\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "    ])\n",
        "\n",
        "# Dataset\n",
        "data_path = \"/content/drive/My Drive/Datasets/MyDatasets/PlantVillage\"\n",
        "dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
        "\n",
        "subset_size = min(2000, len(dataset))  # keep small for quick runs\n",
        "train_size = int(0.8 * subset_size)\n",
        "val_size   = subset_size - train_size\n",
        "small_dataset, _ = random_split(dataset, [subset_size, len(dataset)-subset_size])\n",
        "train_dataset, val_dataset = random_split(small_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"Classes:\", dataset.classes)\n",
        "\n",
        "# CNN for 128×128\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, num_classes, in_channels=1):\n",
        "        super(SmallCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # 128 -> 64 -> 32 after 2 poolings\n",
        "        self.fc1 = nn.Linear(32 * 32 * 32, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))   # 128→64\n",
        "        x = self.pool(self.relu(self.conv2(x)))   # 64→32\n",
        "        x = x.view(x.size(0), -1)                 # flatten\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Training on:\", device)\n",
        "\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, correct, total = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
        "              f\"Train Acc: {train_acc:.2f}%, \"\n",
        "              f\"Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "# Run training\n",
        "num_classes = len(dataset.classes)\n",
        "model = SmallCNN(num_classes=num_classes, in_channels=channels)\n",
        "train_model(model, train_loader, val_loader, epochs=10)"
      ],
      "metadata": {
        "id": "v2_tr5_NcQCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Config: choose RGB or Gray\n",
        "use_gray = True   # set False if you want RGB\n",
        "\n",
        "if use_gray:\n",
        "    channels = 1\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.Resize((128, 128)),   # now 128×128\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    ])\n",
        "else:\n",
        "    channels = 3\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
        "    ])\n",
        "\n",
        "# Dataset\n",
        "data_path = \"/content/drive/My Drive/Datasets/MyDatasets/PlantVillage\"\n",
        "dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
        "\n",
        "subset_size = min(2000, len(dataset))  # keep small for quick runs\n",
        "train_size = int(0.8 * subset_size)\n",
        "val_size   = subset_size - train_size\n",
        "small_dataset, _ = random_split(dataset, [subset_size, len(dataset)-subset_size])\n",
        "train_dataset, val_dataset = random_split(small_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(\"Classes:\", dataset.classes)\n",
        "\n",
        "# CNN for 128×128\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, num_classes, in_channels=1):\n",
        "        super(SmallCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # 128 -> 64 -> 32 after 2 poolings\n",
        "        self.fc1 = nn.Linear(32 * 32 * 32, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))   # 128→64\n",
        "        x = self.pool(self.relu(self.conv2(x)))   # 64→32\n",
        "        x = x.view(x.size(0), -1)                 # flatten\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, val_loader, epochs=5, lr=0.001):\n",
        "    # auto detect cuda\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Training on:\", device)\n",
        "\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, correct, total = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
        "              f\"Train Acc: {train_acc:.2f}%, \"\n",
        "              f\"Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "# Run training\n",
        "num_classes = len(dataset.classes)\n",
        "model = SmallCNN(num_classes=num_classes, in_channels=channels)\n",
        "train_model(model, train_loader, val_loader, epochs=5)\n"
      ],
      "metadata": {
        "id": "cJJJSkdscQEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "save_path = \"plant_cnn.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model saved to {save_path}\")\n",
        "\n",
        "# Load model later\n",
        "# To reload, create the same model architecture first:\n",
        "loaded_model = SmallCNN(num_classes=num_classes, in_channels=channels)\n",
        "loaded_model.load_state_dict(torch.load(save_path))\n",
        "loaded_model.eval()  # set to evaluation mode\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "id": "bffU6HqDcGg4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
